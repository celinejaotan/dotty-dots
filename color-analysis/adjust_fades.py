#!/usr/bin/env python

# After editing 80+ characters, it turns out that the submitted
# fade values are scattered all over the place - and almost useless.
# With some characters all light, and other all very dark.
#
# This script will take the alphabet.js file (with fades as input by
# the user) and scale the fade for each dot to approximate the same
# fade spread that was used in the original blue letters from the 
# google logo.
#
# The approach is over-complicated and messy. I'd recommend you don't
# use any of this. I just wanted to experiment with numpy, matplotlib, etc..
# 
# This tool:
#  - Loads the alphabet.js file
#  - Converts any RGBs to HLSs
#  - Normalizes the known 'blues' to a least-squares best-fit line.
#  - Finds a cumulative distribution function (CDF) for pixel color on this line
#  - For each character:
#           - fits the dots to the alphabets' own best fit line
#			- Calculates the character's pixel CDF along this line 
#  			- "bends" the Character CDF towards the blues' CDF
#			- For each dot, recalculates the fade value using the bent CDF.
#  - Saves alphabet_refaded.js

import sys
import csv
import copy
import colorsys

import numpy as np
import matplotlib.pyplot as plt
import pylab
import mpl_toolkits.mplot3d as m3d

def fetch_rgbs(filename):
	r = []
	sizes = []
	csvreader = csv.reader(open(filename),delimiter='\t')
	for row in csvreader:
		if len(row) == 0:
			continue
		elif row[0] == 'R':
			continue
		
		fro = [ float(x) for x in row[:3] ]
		sizes.append(float(row[3]))
			
		r.append( list(fro) )
		
	return ( np.array(r), sizes )
	
	
def fetch_rgbs_from_alphabet(alphabet):
	r = []
	sizes = []
	for chardata in alphabet.itervalues():
		for point in chardata["P"]:
			fade = point[3]
			size = point[2]
			sizes.append( float(size) )
			r.append( [ 255.0 - float(fade), 0.0, 0.0 ])
	return (np.array(r), sizes)
		
			
def load_alphabet_js(filename='alphabet.js'):
	js = open(filename,'r').read()
	js = js.strip()
	js = js[js.find("=")+2:]
	js = js[:-2]
	js = js.replace("},A","}\nA")
	charjs_es = js.split("\n")

	a = {}

	for charjs in charjs_es:
		charcode = charjs[:charjs.find(":")]
		chardata = charjs[charjs.find(":")+1:]
		w_frag = chardata[1:chardata.find(",")]
		width = int(w_frag.split(":")[1])
		p_frag = chardata[chardata.find(",")+1:-1].split(":")[1]
		p_frag = p_frag[1:-1]
		p_frag = p_frag.replace("],[","]\n[")
		points = p_frag.split("\n")
		decoded_p = []
		if len(p_frag) > 0:
			for p in points:
				p = p[1:-1]
				pv = [int(x.strip()) for x in p.split(",")]
				decoded_p.append(pv)
		a[charcode] = {"W":width, "P":decoded_p}
	return a

def dump_alphabet_js(new_alphabet, filename="alphabet_refaded.js"):
	out = "document.alphabet={"
	allchardata = []
	for ccode, cdata in new_alphabet.iteritems():
		data = ""
		data += ccode 
		data += ":{W:%d" % cdata["W"]
		data += ",P:["
		data += ",".join([("[%d,%d,%d,%d]" % (p[0],p[1],p[2],p[3])) for p in cdata["P"] ])
		data += "]}"
		allchardata.append(data)

	out += ",".join(allchardata)
	out += "};"

	ouf = open(filename, 'w')
	ouf.write(out)
	ouf.close()
	
	
	
	
def cast(rgb_to_X, data):
	# Cast rgb data to some colorscheme with the provided rgb_to_X function
	newdata = []
	for row in data:
		new_row = list(  rgb_to_X( row[0]/255.0, row[1]/255.0, row[2]/255.0 ) )
		newdata.append(new_row)
	return np.array(newdata)
		
		
		
def fit(data,title="Title"):
	# Calculate the mean and vector of all points in data.
	datamean = data.mean(axis=0)

	# Do an SVD on the mean-centered data.
	spread = data - datamean	
	uu, dd, vv = np.linalg.svd(spread)

	# Now vv[0] contains the first principal component, i.e. the direction
	# vector of the 'best fit' line in the least squares sense.
	
	""" Commented out graphing.
	
	# Approximate the range over this line...
	sqs = spread[:,0]**2 + spread[:,1]**2 + spread[:,2]**2
	width = sqs**0.5
	mw = max(width)
		
	# Now generate some points along this best fit line, for plotting.
	linepts = vv[0] * np.mgrid[-mw:mw:2j][:, np.newaxis]

	# shift by the mean to get the line in the right place
	linepts += datamean

	ax = m3d.Axes3D(plt.figure())
	ax.scatter3D(*data.T)
	ax.scatter3D(*mapped_points.T)
	ax.plot3D(*linepts.T)
	plt.title(title)
	plt.show()
	"""

	return (datamean, vv[0])
	
	
def get_gamma(point, datamean, vector):
	spread_point = point - datamean	
	gamma = sum(spread_point * vector) / sum(vector**2)
	return gamma
	
	
def normalize(data, datamean, vector):
	# Map the data points to their nearest points
	# i.e. to the line generated by (datamean + gamma * vector)
	
	mapped_points = None
	gammas = []
	for point in data:
		gamma = get_gamma(point, datamean, vector)
		gammas.append(gamma)
		new_point = datamean + (gamma * vector)
		if mapped_points is None:
			mapped_points = new_point.reshape(1,3)
		else:
			mapped_points = np.append(mapped_points, new_point.reshape(1,3)	, 0)
			
	return {"mapped_points":mapped_points,
			"vector": vector,
			"mean": datamean,
			"gammas": gammas}
			
	
def fixup_red_hls(data):
	# Just used on google_reds.txt
	
	# The hue scale wraps around at 1.0, Some reds fall on each side 
	# of that break.
	newd = []
	for dr in data:
		if dr[0] < 0.05:
			dr[0] += 1.0
		newd.append(dr)
	return np.array(newd)
	

def fit_as_hlss(rgbs, sizes):
	hlss = cast(colorsys.rgb_to_hls, rgbs)
	#hlss = fixup_red_hls(hlss)  
	(mean, vector) = fit(hlss)
	return (hlss, mean, vector)
		
		
def get_cdf(fit_data, sizes):
	g = fit_data["gammas"]
	gsize = zip(g, sizes)
	fullsize = sum( [ x**2 for x in sizes] )
	gsize.sort(lambda x,y: cmp(x[0], y[0]))
	
	cdf = []
	prob = 0.0
	for (g, size) in gsize:
		cdf.append( [g, prob])
		prob += size*size / float(fullsize)
		cdf.append( [g, prob] )
	
	return cdf


def write_rgbs( filename, colors):	
	ouf = open(filename,'w')
	ouf.write("R\tG\tB\tSize\n")
	for c in colors:
		ouf.write("%s\t%s\t%s\t%s\n" % (c[0], c[1], c[2], c[3]) )


def rgb_size_data(charcode, alphabet):
	if len(charcode) == 1:
		charcode = "A%x" % ord(charcode)
	data = []
	sizes = []
	char = alphabet[charcode]
	for dot in char["P"]:
		fade = dot[3]
		size = dot[2]
		sizes.append(int(size))
		data.append( [255 - int(fade), 0, 0] )
	return (np.array(data), sizes)
	
	
def reduce_cdf(cdf):
	# The cdf points needed to plot it nicely, are not
	# the ones we need for bending a character CDF to 
	# a given CDF. 
	#
	# This reduces the number of points to work with.
	
	rp = []
	
	#def equals(x,y):
	#	if abs(x-y) < 0.00000001:
	#		return True
	#	return False
		
	last_g = -10000
	last_prob = 0.0
	for (g, prob) in cdf:
		if (last_g != g) and last_prob != 0.0:
			rp.append( [last_g, last_prob] )
			last_g = g
			if prob > last_prob:
				last_prob = prob
		else:
			last_g = g
			last_prob = prob
			
	rp.append( [last_g, last_prob] )		
	return rp
		
	
def main():
	alphabet = load_alphabet_js()
	
	# We adjust the fades in new_alphabet.
	new_alphabet = copy.deepcopy(alphabet)
	
	# Get best fit line for the input fades...
	(rgbs, sizes) = fetch_rgbs_from_alphabet(alphabet)
	(hlss, mean, vector) = fit_as_hlss(rgbs, sizes)
	
	# Get google_blues pixel CDF on bet-fit line...
	(blue_rgbs, blue_sizes) = fetch_rgbs("google_blues.txt")
	(blue_hlss, blue_mean, blue_vector) = fit_as_hlss(blue_rgbs, blue_sizes)
	blue_fit_data = normalize(blue_hlss, blue_mean, blue_vector)
	blue_cdf_plotable = get_cdf(blue_fit_data, blue_sizes)
	blue_cdf = reduce_cdf(blue_cdf_plotable)
	
	print "               \t\t[H, L, S]"
	print "Fitting to mean\t\t%s" % (blue_mean * np.array([[360, 100, 100]]))
	print "Fitting to vector\t%s" % (blue_vector * np.array([[360, 100, 100]]))
	
	for charcode in alphabet.iterkeys():
		char = chr(int(charcode[1:],16))
		
		if len(alphabet[charcode]["P"]) == 0:
			# No points to scale
			continue
			
		(char_rgbs, char_sizes) = rgb_size_data(charcode, alphabet)
		char_hlss = cast(colorsys.rgb_to_hls, char_rgbs)
		# Fit data to the alphabet wide mean/vector.
		fit_data = normalize(char_hlss, mean, vector)
		char_cdf_plotable = get_cdf(fit_data, char_sizes)
		char_cdf = reduce_cdf(char_cdf_plotable)

		def find_gamma(rcdf, tp):
			for (g, prob) in rcdf:
				if prob < tp:
					continue
				else:
					return g
			# Didn't find gamma
			print "\n\n"
			print rcdf
			raise Exception("No gamma? tp=%s" % tp)

		# Bend char_cdf towards blue_cdf...
		bent_cdf = []
		last_prob = 0.0
		old_gs = []
		new_gs = []
		for (g, prob) in char_cdf:
			try:
				old_gs.append(g)
				mid_prob = (last_prob + prob) / 2.0
				new_g = find_gamma(blue_cdf, mid_prob)
				new_gs.append(new_g)
				bent_cdf.append( [new_g, prob] )
				last_prob = prob
			except:
				print "last_prob = %s" % last_prob
				print "prob = %s" % prob
				raise
			
		# Now apply the bent_cdf to each dot...	
		for point in new_alphabet[charcode]["P"]:
			fade = float(point[3])
			hls = colorsys.rgb_to_hls( (255 - fade)/255.0, 0.0, 0.0 )
			hls_point = np.array( list(hls) )
			orig_gamma = get_gamma(hls_point, mean, vector)
			
			index = old_gs.index(orig_gamma)
			new_g = new_gs[index]
			
			point[3] = int(round(new_g*1000))
			
			
		""" Comment out plotting the CDF modification...
		
		pylab.title(chr(int(charcode[1:],16)))
		pylab.plot( [x[0] for x in char_cdf_plotable], [x[1] for x in char_cdf_plotable], 'r')
		pylab.plot( [x[0] for x in char_cdf], [x[1] for x in char_cdf], 'y')	
		pylab.plot( [x[0] for x in blue_cdf_plotable], [x[1] for x in blue_cdf_plotable], 'b')
		pylab.plot( [x[0] for x in bent_cdf], [x[1] for x in bent_cdf], 'g')
		pylab.show()
		"""
		
	dump_alphabet_js(new_alphabet)

if __name__ == '__main__':
	main()